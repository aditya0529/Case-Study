import boto3
import logging
import os
from datetime import datetime, timezone
from dateutil.relativedelta import relativedelta
from botocore.exceptions import ClientError

# Initialize AWS clients
iam_client = boto3.client('iam')
securityhub_client = boto3.client('securityhub')

# Configure logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Read configuration from environment variables
ROTATION_THRESHOLD_MONTHS = int(os.environ.get('ROTATION_THRESHOLD_MONTHS', '23'))
SEVERITY_THRESHOLD = os.environ.get('SEVERITY_THRESHOLD', 'HIGH')

# ---------- Helper Functions ----------

def get_account_id_and_region(context):
    """Extract AWS account ID and region from the Lambda context."""
    logger.info("Extracting AWS account ID and region from the context.")
    arn_parts = context.invoked_function_arn.split(":")
    region = arn_parts[3]
    account_id = arn_parts[4]
    logger.info(f"Extracted account ID: {account_id} and region: {region}.")
    return account_id, region

def list_all_users():
    """List all IAM users."""
    logger.info("Listing all IAM users.")
    users = []
    paginator = iam_client.get_paginator('list_users')
    for page in paginator.paginate():
        users.extend(page['Users'])
    logger.info(f"Total IAM users retrieved: {len(users)}.")
    return users

def list_access_keys_for_user(user_name):
    """List all access keys for a given IAM user."""
    logger.info(f"Listing access keys for user: {user_name}.")
    access_keys = []
    key_paginator = iam_client.get_paginator('list_access_keys')
    for key_page in key_paginator.paginate(UserName=user_name):
        access_keys.extend(key_page['AccessKeyMetadata'])
    logger.info(f"User {user_name} has {len(access_keys)} access keys.")
    return access_keys

def is_key_non_compliant(key, rotation_threshold_date):
    """Check if an access key is non-compliant."""
    non_compliant = key['Status'] == 'Active' and key['CreateDate'] < rotation_threshold_date
    key_id = key['AccessKeyId']
    if non_compliant:
        logger.debug(f"Access key {key_id} is non-compliant.")
    else:
        logger.debug(f"Access key {key_id} is compliant.")
    return non_compliant

def construct_finding(user_name, key, key_age_days, account_id, region, product_arn):
    """Construct a Security Hub finding for a non-compliant access key."""
    logger.info(f"Constructing finding for user: {user_name}, key ID: {key['AccessKeyId']}.")
    key_id = key['AccessKeyId']
    finding = {
        "SchemaVersion": "2018-10-08",
        "Id": f"{user_name}/{key_id}",
        "ProductArn": product_arn,
        "GeneratorId": "iam-access-key-rotation-check",
        "AwsAccountId": account_id,
        "Types": ["Software and Configuration Checks/AWS Security Best Practices"],
        "CreatedAt": datetime.now(timezone.utc).isoformat(),
        "UpdatedAt": datetime.now(timezone.utc).isoformat(),
        "Severity": {"Label": SEVERITY_THRESHOLD},
        "Title": "IAM Access Key Rotation Best Practice Violation",
        "Description": (
            f"Active IAM access key {key_id} for user {user_name} is older than "
            f"{ROTATION_THRESHOLD_MONTHS} months (Key Age: {key_age_days} days)."
        ),
        "Resources": [
            {
                "Type": "AwsIamAccessKey",
                "Id": f"arn:aws:iam::{account_id}:user/{user_name}",
                "Partition": "aws",
                "Region": region,
                "Details": {
                    "AwsIamAccessKey": {
                        "UserName": user_name,
                        "Status": key['Status'],
                        "CreatedAt": key['CreateDate'].replace(tzinfo=timezone.utc).isoformat(),
                        "AccessKeyId": key_id
                    }
                }
            }
        ],
        "Compliance": {"Status": "FAILED"},
        "Workflow": {"Status": "NEW"},
        "RecordState": "ACTIVE"
    }
    logger.debug(f"Constructed finding: {finding}.")
    return finding

def finding_exists(finding_id, product_arn):
    """Check if a matching finding already exists in Security Hub."""
    logger.info(f"Checking if finding {finding_id} exists in Security Hub with matching severity and compliance status.")
    try:
        response = securityhub_client.get_findings(
            Filters={
                'Id': [{'Value': finding_id, 'Comparison': 'EQUALS'}],
                'ProductArn': [{'Value': product_arn, 'Comparison': 'EQUALS'}],
                'SeverityLabel': [{'Value': SEVERITY_THRESHOLD, 'Comparison': 'EQUALS'}],
                'ComplianceStatus': [{'Value': 'FAILED', 'Comparison': 'EQUALS'}],
                'WorkflowStatus': [{'Value': 'NEW', 'Comparison': 'EQUALS'}],
                'RecordState': [{'Value': 'ACTIVE', 'Comparison': 'EQUALS'}]
            }
        )
        exists = len(response['Findings']) > 0
        if exists:
            logger.info(f"Matching finding {finding_id} already exists in Security Hub.")
        else:
            logger.info(f"No matching finding {finding_id} found in Security Hub.")
        return exists
    except ClientError as e:
        logger.error(f"Error checking existence of finding {finding_id}: {e}")
        return False

def get_existing_findings(account_id, region, product_arn):
    """Retrieve existing findings related to IAM access keys."""
    logger.info("Retrieving existing findings from Security Hub.")
    findings = []
    paginator = securityhub_client.get_paginator('get_findings')
    for page in paginator.paginate(
        Filters={
            'GeneratorId': [{'Value': 'iam-access-key-rotation-check', 'Comparison': 'EQUALS'}],
            'ProductArn': [{'Value': product_arn, 'Comparison': 'EQUALS'}],
            'RecordState': [{'Value': 'ACTIVE', 'Comparison': 'EQUALS'}]
        }
    ):
        findings.extend(page['Findings'])
    logger.info(f"Total existing findings retrieved: {len(findings)}.")
    return findings

def update_finding_to_new_and_archived(finding_id, product_arn):
    """Update the Security Hub finding to NEW and ARCHIVED."""
    logger.info(f"Updating finding {finding_id} to NEW and ARCHIVED.")
    try:
        securityhub_client.batch_update_findings(
            FindingIdentifiers=[{'Id': finding_id, 'ProductArn': product_arn}],
            Workflow={'Status': 'NEW'},
            RecordState='ARCHIVED'
        )
        logger.info(f"Finding {finding_id} updated to NEW and ARCHIVED.")
    except ClientError as e:
        logger.error(f"Error updating finding {finding_id}: {e}")

def create_access_key_deletion_finding(user_name, access_key_id, account_id, region, product_arn):
    """Create an informational finding to document that an access key was deleted."""
    logger.info(f"Creating deletion finding for access key {access_key_id} of user {user_name}.")
    finding_id = f"{user_name}/{access_key_id}-deletion-proof"
    finding = {
        "SchemaVersion": "2018-10-08",
        "Id": finding_id,
        "ProductArn": product_arn,
        "GeneratorId": "iam-access-key-deletion-proof",
        "AwsAccountId": account_id,
        "Types": ["Effects/Data Exposure"],
        "CreatedAt": datetime.now(timezone.utc).isoformat(),
        "UpdatedAt": datetime.now(timezone.utc).isoformat(),
        "Severity": {"Label": "INFORMATIONAL"},
        "Title": "IAM Access Key Deletion Proof",
        "Description": f"IAM access key {access_key_id} for user {user_name} has been deleted.",
        "Resources": [
            {
                "Type": "AwsIamAccessKey",
                "Id": f"arn:aws:iam::{account_id}:user/{user_name}",
                "Partition": "aws",
                "Region": region,
                "Details": {
                    "AwsIamAccessKey": {
                        "UserName": user_name,
                        "Status": "Deleted",
                        "AccessKeyId": access_key_id
                    }
                }
            }
        ],
        "Compliance": {"Status": "NOT_AVAILABLE"},
        "Workflow": {"Status": "NEW"},
        "RecordState": "ACTIVE"
    }
    try:
        securityhub_client.batch_import_findings(Findings=[finding])
        logger.info(f"Deletion finding {finding_id} created in Security Hub.")
    except ClientError as e:
        logger.error(f"Error creating deletion finding {finding_id}: {e}")

def get_non_compliant_findings(rotation_threshold_date, account_id, region, product_arn):
    """Retrieve non-compliant IAM access keys and construct findings."""
    logger.info("Retrieving non-compliant IAM access keys.")
    non_compliant_findings = []
    users = list_all_users()
    existing_keys = set()
    for user in users:
        user_name = user['UserName']
        logger.info(f"Processing user: {user_name}.")
        try:
            access_keys = list_access_keys_for_user(user_name)
            for key in access_keys:
                key_id = key['AccessKeyId']
                existing_keys.add(f"{user_name}/{key_id}")
                if is_key_non_compliant(key, rotation_threshold_date):
                    key_age_days = (datetime.now(timezone.utc) - key['CreateDate']).days
                    finding_id = f"{user_name}/{key_id}"
                    if not finding_exists(finding_id, product_arn):
                        finding = construct_finding(user_name, key, key_age_days, account_id, region, product_arn)
                        non_compliant_findings.append(finding)
                        logger.info(f"Added finding for user {user_name}, key {key_id}.")
                    else:
                        logger.info(f"Finding {finding_id} already exists with matching attributes. Skipping.")
        except ClientError as e:
            logger.error(f"Error retrieving access keys for user {user_name}: {e}")
            continue
    logger.info(f"Total non-compliant findings to send: {len(non_compliant_findings)}.")
    return non_compliant_findings, existing_keys

def send_findings_to_security_hub(findings):
    """Send the non-compliant findings to AWS Security Hub."""
    if not findings:
        logger.info("No new findings to send to Security Hub.")
        return

    batch_size = 100
    logger.info(f"Sending {len(findings)} findings to Security Hub in batches of {batch_size}.")
    for i in range(0, len(findings), batch_size):
        batch = findings[i:i+batch_size]
        try:
            securityhub_client.batch_import_findings(Findings=batch)
            logger.info(f"Successfully sent batch of {len(batch)} findings to Security Hub.")
        except ClientError as e:
            logger.error(f"Error sending findings to Security Hub: {e}")

def handle_scheduled_event(account_id, region, product_arn):
    """Handle scheduled events for daily non-compliance checks."""
    logger.info("Handling scheduled event for daily non-compliance check.")
    rotation_threshold_date = datetime.now(timezone.utc) - relativedelta(months=ROTATION_THRESHOLD_MONTHS)
    logger.info(f"Rotation threshold date is set to: {rotation_threshold_date}.")

    # Get existing findings from Security Hub
    existing_findings = get_existing_findings(account_id, region, product_arn)
    existing_finding_ids = set(f['Id'] for f in existing_findings)
    logger.info(f"Existing finding IDs: {existing_finding_ids}")

    # Get non-compliant access keys and existing keys
    non_compliant_findings, existing_keys = get_non_compliant_findings(rotation_threshold_date, account_id, region, product_arn)

    # Send new findings to Security Hub
    send_findings_to_security_hub(non_compliant_findings)

    # For existing findings, check if the access key still exists
    for finding in existing_findings:
        finding_id = finding['Id']
        if finding_id not in existing_keys:
            # Access key no longer exists
            user_name, access_key_id = finding_id.split('/', 1)
            logger.info(f"Access key {access_key_id} for user {user_name} no longer exists. Updating finding.")
            # Update the existing finding to 'ARCHIVED'
            update_finding_to_new_and_archived(finding_id, product_arn)
            # Create a deletion proof finding
            create_access_key_deletion_finding(user_name, access_key_id, account_id, region, product_arn)
        else:
            logger.info(f"Access key {finding_id} still exists.")

    logger.info("Daily non-compliance check completed.")

# ---------- Lambda Handler ----------

def lambda_handler(event, context):
    """Main Lambda handler for scheduled checks."""
    logger.info("Starting IAM access key compliance check.")
    logger.info(f"Received event: {event}")  # Log the event for testing purposes
    account_id, region = get_account_id_and_region(context)
    product_arn = f"arn:aws:securityhub:{region}:{account_id}:product/{account_id}/default"

    try:
        # Handle scheduled event
        logger.info("Scheduled trigger detected. Initiating daily compliance check.")
        handle_scheduled_event(account_id, region, product_arn)
        return {'statusCode': 200, 'message': 'Daily compliance check completed.'}

    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")
        return {'statusCode': 500, 'message': 'An unexpected error occurred while processing the request.'}
